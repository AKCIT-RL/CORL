{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "from etils import epath\n",
    "from tqdm import tqdm\n",
    "\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from mujoco_playground.config import locomotion_params, manipulation_params\n",
    "\n",
    "from mujoco_playground import registry\n",
    "from mujoco_playground import wrapper, wrapper_torch\n",
    "\n",
    "import mediapy as media\n",
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco.egl\n",
    "gl_context = mujoco.egl.GLContext(1024, 1024)\n",
    "gl_context.make_current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = [\n",
    "    # {'env': 'Go2JoystickFlatTerrain', \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickFlatTerrain-20250818-065703/checkpoints\"},\n",
    "    # {'env': 'Go2JoystickFlatTerrain', \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickFlatTerrain-20250818-115104/checkpoints\"},\n",
    "    # {'env': 'Go2JoystickFlatTerrain', \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickFlatTerrain-20250818-125223/checkpoints\"},\n",
    "    # {'env': 'Go2JoystickFlatTerrain', \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickFlatTerrain-20250818-135346/checkpoints\"},\n",
    "    # {'env': 'Go2JoystickFlatTerrain', \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickFlatTerrain-20250818-145517/checkpoints\"}, \n",
    "\n",
    "    # {\"env\": \"Go2JoystickRoughTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickRoughTerrain-20250818-155634/checkpoints\"}, \n",
    "    # {\"env\": \"Go2JoystickRoughTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickRoughTerrain-20250818-172316/checkpoints\"}, \n",
    "    # {\"env\": \"Go2JoystickRoughTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickRoughTerrain-20250818-184955/checkpoints\"}, \n",
    "    # {\"env\": \"Go2JoystickRoughTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickRoughTerrain-20250818-201636/checkpoints\"}, \n",
    "    # {\"env\": \"Go2JoystickRoughTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2JoystickRoughTerrain-20250818-214317/checkpoints\"},\n",
    "\n",
    "    # {\"env\": \"Go2Getup\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Getup-20250816-191527/checkpoints\"},\n",
    "    # {\"env\": \"Go2Getup\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Getup-20250817-104354/checkpoints\"},\n",
    "    # {\"env\": \"Go2Getup\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Getup-20250817-123933/checkpoints\"},\n",
    "    # {\"env\": \"Go2Getup\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Getup-20250817-172203/checkpoints\"},\n",
    "    # {\"env\": \"Go2Getup\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Getup-20250819-091222/checkpoints\"},\n",
    "\n",
    "    # {\"env\": \"Go2Handstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Handstand-20250818-231000/checkpoints\"},\n",
    "    # {\"env\": \"Go2Handstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Handstand-20250819-010441/checkpoints\"},\n",
    "    # {\"env\": \"Go2Handstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Handstand-20250819-025956/checkpoints\"},\n",
    "    # {\"env\": \"Go2Handstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Handstand-20250819-045444/checkpoints\"},\n",
    "    # {\"env\": \"Go2Handstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Handstand-20250819-064935/checkpoints\"},\n",
    "\n",
    "    # {\"env\": \"Go2Footstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Footstand-20250817-212125/checkpoints\"},\n",
    "    # {\"env\": \"Go2Footstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Footstand-20250817-231711/checkpoints\"},\n",
    "    # {\"env\": \"Go2Footstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Footstand-20250818-011229/checkpoints\"},\n",
    "    # {\"env\": \"Go2Footstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Footstand-20250818-030725/checkpoints\"},\n",
    "    # {\"env\": \"Go2Footstand\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go2Footstand-20250818-050219/checkpoints\"},\n",
    "\n",
    "    # {\"env\": \"G1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/G1JoystickFlatTerrain-20250806-214823/checkpoints\"},\n",
    "    # {\"env\": \"G1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/G1JoystickFlatTerrain-20250811-163413/checkpoints\"},\n",
    "    # {\"env\": \"G1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/G1JoystickFlatTerrain-20250811-163423/checkpoints\"},\n",
    "    # {\"env\": \"G1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/G1JoystickFlatTerrain-20250813-183648/checkpoints\"},\n",
    "    # {\"env\": \"G1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/G1JoystickFlatTerrain-20250815-174612/checkpoints\"}\n",
    "\n",
    "    {\"env\": \"Go1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go1JoystickFlatTerrain-20250830-150709/checkpoints\"},\n",
    "    {\"env\": \"Go1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go1JoystickFlatTerrain-20250830-151333/checkpoints\"},\n",
    "    {\"env\": \"Go1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go1JoystickFlatTerrain-20250831-133829/checkpoints\"},\n",
    "    {\"env\": \"Go1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go1JoystickFlatTerrain-20250831-133902/checkpoints\"},\n",
    "    {\"env\": \"Go1JoystickFlatTerrain\", \"model\": \"PPO\", \"checkpoint_path\": \"../expert/logs/Go1JoystickFlatTerrain-20250831-162833/checkpoints\"}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in path_model:\n",
    "    print(\"-\"*100)\n",
    "    print(f\"ENV: {p['env']}\")\n",
    "    print(\"-\"*100)\n",
    "    print()\n",
    "\n",
    "    env = registry.load(p[\"env\"])\n",
    "    env_cfg = registry.get_default_config(p[\"env\"])\n",
    "    randomizer = registry.get_domain_randomizer(p[\"env\"])\n",
    "\n",
    "\n",
    "    # ------------- EXPERT EVALUATION\n",
    "    ckpt_path = str(epath.Path(p[\"checkpoint_path\"]).resolve())\n",
    "    FINETUNE_PATH = epath.Path(ckpt_path)\n",
    "    latest_ckpts = list(FINETUNE_PATH.glob(\"*\"))\n",
    "    latest_ckpts = [ckpt for ckpt in latest_ckpts if ckpt.is_dir()]\n",
    "    latest_ckpts.sort(key=lambda x: int(x.name))\n",
    "    latest_ckpt = latest_ckpts[-1]\n",
    "    restore_checkpoint_path = latest_ckpt\n",
    "\n",
    "    try:\n",
    "        ppo_params = locomotion_params.brax_ppo_config(p[\"env\"])\n",
    "    except:\n",
    "        ppo_params = manipulation_params.brax_ppo_config(p[\"env\"])\n",
    "\n",
    "    ppo_training_params = dict(ppo_params)\n",
    "    ppo_training_params[\"num_timesteps\"] = 0\n",
    "\n",
    "    if \"policy_hidden_layer_sizes\" in p:\n",
    "        ppo_params[\"network_factory\"][\"policy_hidden_layer_sizes\"] = p[\"policy_hidden_layer_sizes\"]\n",
    "\n",
    "    network_factory = ppo_networks.make_ppo_networks\n",
    "    if \"network_factory\" in ppo_params:\n",
    "        del ppo_training_params[\"network_factory\"]\n",
    "        network_factory = functools.partial(\n",
    "            ppo_networks.make_ppo_networks, **ppo_params.network_factory\n",
    "        )\n",
    "\n",
    "    train_fn = functools.partial(\n",
    "        ppo.train,\n",
    "        **dict(ppo_training_params),\n",
    "        network_factory=network_factory,\n",
    "        randomization_fn=randomizer,\n",
    "    )\n",
    "\n",
    "    make_inference_fn, params, metrics = train_fn(\n",
    "        environment=registry.load(p[\"env\"]),\n",
    "        eval_env=registry.load(p[\"env\"]),\n",
    "        wrap_env_fn=wrapper.wrap_for_brax_training,\n",
    "        restore_checkpoint_path=restore_checkpoint_path,\n",
    "        seed=1,\n",
    "    )\n",
    "\n",
    "    jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))\n",
    "    \n",
    "    def eval_expert(env, n_episodes, jit_inference_fn):\n",
    "        jit_reset = jax.jit(env.reset)\n",
    "        jit_step = jax.jit(env.step)\n",
    "        rng = jax.random.PRNGKey(0)\n",
    "\n",
    "        rollout = []\n",
    "        episode_rewards = []\n",
    "        for _ in tqdm(range(n_episodes)):\n",
    "            rng, reset_rng = jax.random.split(rng)\n",
    "            state = jit_reset(reset_rng)\n",
    "\n",
    "            rollout.append(state)\n",
    "            done = False\n",
    "            episode_reward = 0.0\n",
    "            for i in range(env_cfg.episode_length):\n",
    "                act_rng, rng = jax.random.split(rng)\n",
    "                action, _ = jit_inference_fn(state.obs, act_rng)\n",
    "                state = jit_step(state, action)\n",
    "                rollout.append(state)\n",
    "                episode_reward += wrapper_torch._jax_to_torch(state.reward).cpu().numpy()\n",
    "                done = bool(wrapper_torch._jax_to_torch(state.done).cpu().numpy().item())\n",
    "                if done:\n",
    "                    break\n",
    "            episode_rewards.append(episode_reward)\n",
    "\n",
    "        return np.asarray(episode_rewards), rollout\n",
    "    \n",
    "    episode_rewards, rollout = eval_expert(env, 20, jit_inference_fn)\n",
    "    p[\"episode_rewards_mean\"] = episode_rewards.mean()\n",
    "    p[\"episode_rewards_std\"] = episode_rewards.std()\n",
    "\n",
    "    render_every = 2\n",
    "    fps = 1.0 / env.dt / render_every\n",
    "    traj = rollout[::render_every]\n",
    "\n",
    "    scene_option = mujoco.MjvOption()\n",
    "    scene_option.geomgroup[2] = True\n",
    "    scene_option.geomgroup[3] = False\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = True\n",
    "\n",
    "    try:\n",
    "        frames = env.render(\n",
    "            traj,\n",
    "            camera=\"track\",\n",
    "            scene_option=scene_option,\n",
    "            width=640,\n",
    "            height=480,\n",
    "        )\n",
    "    except:\n",
    "        render_every = 1\n",
    "        frames = env.render(rollout[::render_every])\n",
    "\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    media.write_video(f\"../expert/rollouts/expert_rollout-{p['env']}-{timestamp}.mp4\", frames, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(path_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "offlinerl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
