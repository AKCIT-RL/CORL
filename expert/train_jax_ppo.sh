python train_jax_ppo.py --env_name Go2Footstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 1 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Footstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 2 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Footstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 3 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Footstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 4 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Footstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 5 \
    --num_timesteps 200000000


python train_jax_ppo.py --env_name Go2Handstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 1 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Handstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 2 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Handstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 3 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Handstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 4 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Handstand  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 5 \
    --num_timesteps 200000000


python train_jax_ppo.py --env_name Go2Getup  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 1 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Getup  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 2 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Getup  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 3 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Getup  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 4 \
    --num_timesteps 200000000

python train_jax_ppo.py --env_name Go2Getup  --use_wandb \
    --episode_length 2000 \
    --learning_rate 1e-4 \
    --entropy_cost 0.02 \
    --max_grad_norm 2.0 \
    --num_evals 20 \
    --num_minibatches 64 \
    --num_updates_per_batch 8 \
    --unroll_length 40 \
    --reward_scaling 2.0 \
    --num_envs 16384 \
    --value_obs_key 'state' \
    --seed 5 \
    --num_timesteps 200000000